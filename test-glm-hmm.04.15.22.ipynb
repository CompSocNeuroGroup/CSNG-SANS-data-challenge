{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Mar 31 11:19:36 2022\n",
    "@author: jthompsz\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import cm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nibabel as nib\n",
    "import nilearn as ni\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "\n",
    "from hmmlearn import hmm\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore, pearsonr, spearmanr\n",
    "from scipy.spatial.distance import hamming\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "\n",
    "from fnl_tools.stats import hmm_bic\n",
    "from nltools.mask import expand_mask, collapse_mask\n",
    "from nltools.stats import (fisher_r_to_z,\n",
    "                           correlation_permutation)\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "npr.seed(0)\n",
    "\n",
    "import ssm\n",
    "from ssm.util import find_permutation\n",
    "from ssm.plots import gradient_cmap, white_to_color_cmap\n",
    "color_names = [\n",
    "    \"windows blue\",\n",
    "    \"red\",\n",
    "    \"amber\",\n",
    "    \"faded green\",\n",
    "    \"dusty purple\",\n",
    "    \"orange\"\n",
    "    ]\n",
    "\n",
    "colors = sns.xkcd_palette(color_names)\n",
    "cmap = gradient_cmap(colors)\n",
    "\n",
    "base_dir = '/mnt/EE9A47C59A478953/data/FNL'\n",
    "out_dir = '/mnt/EE9A47C59A478953/data/FNL/output'\n",
    "func_data = '/data/train'\n",
    "test_data = '/data/test'\n",
    "\n",
    "os.chdir(f'{base_dir}')\n",
    "\n",
    "# load in target ROI\n",
    "target_roi = image.load_img(f'{base_dir}/ROIs/vmpfc-chang.nii.gz')\n",
    "plotting.plot_roi(target_roi)\n",
    "\n",
    "# load source ROIs\n",
    "atlas = image.load_img(f'{base_dir}/ROIs/source_target_rois.nii.gz')\n",
    "plotting.plot_roi(atlas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####               Group-based Analyses - Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a file list of data files\n",
    "file_list = glob.glob(f'{base_dir}{func_data}/sub-*nii.gz')\n",
    "\n",
    "# make ROIs\n",
    "target_masker = NiftiMasker(mask_img=target_roi, standardize=False)\n",
    "masker = NiftiLabelsMasker(labels_img=atlas, standardize=False)\n",
    "\n",
    "target_data = {}\n",
    "source_data = {}\n",
    "target_group_data = pd.DataFrame()\n",
    "source_group_data = pd.DataFrame()\n",
    "for f in tqdm(file_list):  \n",
    "    \n",
    "    sub = f.partition(\"sub-\")[2].rpartition('_task')[0]\n",
    "    # load in data\n",
    "    sdata = image.load_img(f)\n",
    "\n",
    "    # extract target data from roi\n",
    "    #target_time_series = target_masker.fit_transform(sdata)\n",
    "    #target_data = pd.DataFrame(zscore(target_time_series))\n",
    "    #target_data['Subject'] = sub\n",
    "    #target_group_data = target_group_data.append(target_data)\n",
    "    \n",
    "    # extract source data from rois\n",
    "    source_time_series = masker.fit_transform(sdata)\n",
    "    source_data = pd.DataFrame(zscore(source_time_series))\n",
    "    source_data['Subject'] = sub\n",
    "    source_group_data = source_group_data.append(source_data)\n",
    "\n",
    "source_group_data.columns = ['Amygdala', 'NAcc', 'Hippocampus', 'DLPFC', 'DMPFC', 'pInsula', 'TPJ', 'vmpfc','Subject']      \n",
    "source_group_data.to_csv(os.path.join(out_dir, f'train_sources_zscoredata.csv'))\n",
    "target_group_data.to_csv(os.path.join(out_dir, f'vmpfc_rawdata.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###              Load in and extract Test data 04.06.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a file list of data files\n",
    "file_list = glob.glob(f'{base_dir}{test_data}/sub-*nii.gz')\n",
    "\n",
    "# make ROIs\n",
    "target_masker = NiftiMasker(mask_img=target_roi, standardize=False)\n",
    "masker = NiftiLabelsMasker(labels_img=atlas, standardize=False)\n",
    "\n",
    "target_data = {}\n",
    "source_data = {}\n",
    "target_group_data = pd.DataFrame()\n",
    "source_group_data = pd.DataFrame()\n",
    "for f in tqdm(file_list):  \n",
    "    \n",
    "    sub = f.partition(\"sub-\")[2].rpartition('_task')[0]\n",
    "    # load in data\n",
    "    sdata = image.load_img(f)\n",
    "\n",
    "    # extract target data from roi\n",
    "    target_time_series = target_masker.fit_transform(sdata)\n",
    "    target_data = pd.DataFrame(zscore(target_time_series))\n",
    "    target_data['Subject'] = sub\n",
    "    target_group_data = target_group_data.append(target_data)\n",
    "    \n",
    "    # extract source data from rois\n",
    "    source_time_series = masker.fit_transform(sdata)\n",
    "    source_data = pd.DataFrame(zscore(source_time_series))\n",
    "    source_data['Subject'] = sub\n",
    "    source_group_data = source_group_data.append(source_data)\n",
    "\n",
    "source_group_data.columns = ['Amygdala', 'NAcc', 'Hippocampus', 'DLPFC', 'DMPFC', 'pInsula', 'TPJ', 'vmpfc','Subject']      \n",
    "source_group_data.to_csv(os.path.join(out_dir, f'test_sources_zscoredata.csv'))\n",
    "\n",
    "target_group_data.to_csv(os.path.join(out_dir, f'test_vmpfc_rawdata.csv'))\n",
    "\n",
    "# Train PCA on training data, apply to test data and save\n",
    "#training = pd.read_csv(os.path.join(out_dir, f'vmpfc_rawdata.csv'), index_col=0)\n",
    "#test = pd.read_csv(os.path.join(out_dir, f'test_vmpfc_rawdata.csv'), index_col=0)\n",
    "\n",
    "# Reduce Data Dimensionality, train on training and apply to test\n",
    "#target_var = 0.9\n",
    "#pca = PCA(n_components=target_var)\n",
    "\n",
    "#training_fit = pca.fit(training.drop(columns='Subject'))\n",
    "#training_comps = pca.transform(training.drop(columns='Subject'))\n",
    "#test_comps = pca.transform(test.drop(columns='Subject'))\n",
    "        \n",
    "#X = pd.DataFrame(training_comps)\n",
    "#X['Subject'] = training['Subject'].values\n",
    "#X.to_csv(os.path.join(out_dir, f'train_vmpfc_PCdata.csv'))\n",
    "\n",
    "#X = pd.DataFrame(test_comps)\n",
    "#X['Subject'] = test['Subject'].values\n",
    "#X.to_csv(os.path.join(out_dir, f'test_vmpfc_PCdata.csv'))\n",
    "\n",
    "# Train PCA on combined training and test data - tbh I think the above method\n",
    "# would be better, especially with multifold CV. But it yeilds weird results,\n",
    "# I think bc the PCs from train don't quite match the component structure of\n",
    "# test, and I ran out of time trying to understand it fully.\n",
    "\n",
    "training = pd.read_csv(os.path.join(out_dir, f'vmpfc_rawdata.csv'), index_col=0)\n",
    "test = pd.read_csv(os.path.join(out_dir, f'test_vmpfc_rawdata.csv'), index_col=0)\n",
    "all_data = pd.DataFrame()\n",
    "all_data = all_data.append(training)\n",
    "all_data = all_data.append(test)\n",
    "\n",
    "# Reduce Data Dimensionality\n",
    "target_var = 0.9\n",
    "pca = PCA(n_components=target_var)\n",
    "\n",
    "pca_fit = pca.fit_transform(all_data.drop(columns='Subject'))\n",
    "\n",
    "        \n",
    "X = pd.DataFrame(pca_fit[0:training.shape[0],:])\n",
    "X['Subject'] = training['Subject'].values\n",
    "X.to_csv(os.path.join(out_dir, f'train_vmpfc_PCAdata.csv'))\n",
    "\n",
    "X = pd.DataFrame(pca_fit[training.shape[0]:,:])\n",
    "X['Subject'] = test['Subject'].values\n",
    "X.to_csv(os.path.join(out_dir, f'test_vmpfc_PCAdata.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####               Group-based Input-driven HMM as in SSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = pd.read_csv(os.path.join(out_dir, f'train_vmpfc_PCAdata.csv'), index_col=0)\n",
    "source = pd.read_csv(os.path.join(out_dir, f'train_sources_zscoredata.csv'),index_col=0)\n",
    "#source.columns = ['Index', 'Amygdala', 'NAcc', 'Hippocampus', 'DLPFC', 'DMPFC', 'pInsula', 'TPJ', 'Subject']\n",
    "\n",
    "# Let's check the correlations between inputs to the HMM\n",
    "pearsoncorr = source.drop(columns=['Subject']).corr(method='pearson')\n",
    "with sns.plotting_context(context='paper', font_scale=1.5):    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(pearsoncorr, \n",
    "            xticklabels=pearsoncorr.columns,\n",
    "            yticklabels=pearsoncorr.columns,\n",
    "            cmap='RdBu_r',\n",
    "            annot=True,\n",
    "            linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig('Inputs-Correlation4.15.22.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####             Vanilla HMM for group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chang et al (2021) originally found that 4 states was best model, let's check\n",
    "N_iters = 500\n",
    "mle_hmmk = {}\n",
    "bic_hmmk = {}\n",
    "for k in tqdm(range(2, 16)):\n",
    "    hmmk = []\n",
    "    hmmk = ssm.HMM(k, reduced.drop(columns='Subject').shape[1], observations=\"diagonal_gaussian\")\n",
    "    hmmk_fit = hmmk.fit(reduced.drop(columns='Subject').values, method=\"em\", num_iters=N_iters)\n",
    "    mle_hmmk[k] = hmmk.log_likelihood(reduced.drop(columns='Subject').values)\n",
    "    bic_hmmk[k] = hmm_bic(LL=mle_hmmk[k], n_states=k, n_features=reduced.drop(columns='Subject').shape[1])\n",
    "\n",
    "model_fit = pd.DataFrame(list(bic_hmmk.items()))\n",
    "model_fit = model_fit.rename(columns={0: \"k\", 1: \"BIC\"})\n",
    "model_fit.to_csv(os.path.join(out_dir, f'Vanilla-HMM-ModelFitk2-15.csv'))\n",
    "\n",
    "with sns.plotting_context(context='paper', font_scale=2.5):\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    sns.lineplot(data=model_fit, x='k', y='BIC', linewidth=3)\n",
    "    plt.ylabel('Model Fit (BIC)', fontsize=18)\n",
    "    plt.xlabel('k', fontsize=18)\n",
    "    plt.axhline(bic_hmmk[3], color='red', linestyle='--') # red dashed line at k=4\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig('Model Fit-BIC-VanillaHMM4.15.22.png', dpi=150)\n",
    "\n",
    "# With this split half training data, k=3 looks better than k = 4, so will use for the rest of the analyses\n",
    "    \n",
    "# Vanilla HMM for Training Group\n",
    "N_iters = 500\n",
    "k = 3\n",
    "hmm = ssm.HMM(k, reduced.drop(columns='Subject').shape[1], observations=\"diagonal_gaussian\")\n",
    "\n",
    "# Fit\n",
    "hmm_fit = hmm.fit(reduced.drop(columns='Subject').values, method=\"em\", num_iters=N_iters, init_method=\"kmeans\")\n",
    "\n",
    "# Most likely (Viterbi) states\n",
    "hmm_z = hmm.most_likely_states(reduced.drop(columns='Subject').values)\n",
    "\n",
    "# Log Likelihood - when comparing with the input-driven hmm, I'm not 100% on calculation of BIC. Let's use -LL instead, even though it is not ideal.\n",
    "mle_hmm = hmm.log_likelihood(reduced.drop(columns='Subject').values)\n",
    "\n",
    "# Save copy of the hmm\n",
    "filehandler = open(f'{out_dir}/Vanilla-HMM-k3.obj', 'wb')\n",
    "pickle.dump(hmm, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####             Input-HMM for Training Group - AMYG and DMPFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_iters = 500\n",
    "\n",
    "# Amygdala\n",
    "k = 3\n",
    "inputhmm1 = ssm.HMM(k, reduced.drop(columns='Subject').shape[1], source[['Amygdala']].shape[1], observations=\"diagonal_gaussian\", transitions=\"inputdriven\")\n",
    "hmm_amyg = inputhmm1.fit(reduced.drop(columns='Subject').values, inputs=source[['Amygdala']].values, method=\"em\", num_iters=N_iters)\n",
    "mle_amyg = inputhmm1.log_likelihood(reduced.drop(columns='Subject').values, source[['Amygdala']].values)\n",
    "\n",
    "# Save copy of the hmm\n",
    "filehandler = open(f'{out_dir}/Input-HMM-Amygdala-k3.obj', 'wb')\n",
    "pickle.dump(inputhmm1, filehandler)\n",
    "\n",
    "#filein = open(f'{out_dir}/Input-HMM-Amygdala-k3.obj', 'rb')\n",
    "#hmmglm1 = pickle.load(filein)\n",
    "\n",
    "# DMPFC\n",
    "k = 3\n",
    "inputhmm2 = ssm.HMM(k, reduced.drop(columns='Subject').shape[1], source[['DMPFC']].shape[1], observations=\"diagonal_gaussian\", transitions=\"inputdriven\")\n",
    "hmm_dmpfc = inputhmm2.fit(reduced.drop(columns='Subject').values, inputs=source[['DMPFC']].values, method=\"em\", num_iters=N_iters)\n",
    "mle_dmpfc = inputhmm2.log_likelihood(reduced.drop(columns='Subject').values, source[['DMPFC']].values)\n",
    "\n",
    "# Save copy of the hmm\n",
    "filehandler = open(f'{out_dir}/Input-HMM-DMPFC-k3.obj', 'wb')\n",
    "pickle.dump(inputhmm2, filehandler)\n",
    "    \n",
    "# Plot -LL for HMM and Input-HMM models\n",
    "with sns.plotting_context(context='paper', font_scale=2):    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    loglikelihood_vals = [mle_hmm, mle_amyg, mle_dmpfc]\n",
    "    for z, occ in enumerate(loglikelihood_vals):\n",
    "        plt.bar(z, occ, width = 0.8, color = colors[z])\n",
    "    plt.ylim([-6023650, -6023550])\n",
    "    plt.xticks([0,1,2], ['hmm', 'amyg', 'dmpfc'], fontsize = 15)\n",
    "    plt.xlabel('Models (training data)', fontsize = 20)\n",
    "    plt.ylabel('loglikelihood', fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig('ModelFit-TrainData-MLE-k3-4.15.22.png', dpi=150)\n",
    "\n",
    "# Model fit for in-sample data looks best for the dmpfc input-HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Cross-Validation using train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_test = pd.read_csv(os.path.join(out_dir, f'test_vmpfc_PCAdata.csv'), index_col=0)\n",
    "source_test = pd.read_csv(os.path.join(out_dir, f'test_sources_zscoredata.csv'), index_col=0)\n",
    "\n",
    "# Cross-Validated Log Likelihood for the different models - use the model trained on training\n",
    "# data, test on test data\n",
    "mle_hmm_cv = hmm.log_likelihood(reduced_test.drop(columns='Subject').values)\n",
    "\n",
    "mle_amyg_cv = inputhmm1.log_likelihood(reduced_test.drop(columns='Subject').values, source_test[['Amygdala']].values)\n",
    "\n",
    "mle_dmpfc_cv = inputhmm2.log_likelihood(reduced_test.drop(columns='Subject').values, source_test[['DMPFC']].values)\n",
    "\n",
    "# Plot -LL for HMM and Input-HMM models\n",
    "with sns.plotting_context(context='paper', font_scale=2):    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    loglikelihood_vals = [mle_hmm_cv, mle_amyg_cv, mle_dmpfc_cv]\n",
    "    for z, occ in enumerate(loglikelihood_vals):\n",
    "        plt.bar(z, occ, width = 0.8, color = colors[z])\n",
    "    plt.ylim([-6069350, -6069200])\n",
    "    plt.xticks([0,1,2], ['hmm', 'amyg', 'dmpfc'], fontsize = 15)\n",
    "    plt.xlabel('Models (test data)', fontsize = 20)\n",
    "    plt.ylabel('loglikelihood', fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig('ModelFit-TestData-MLE-k3-4.15.22.png', dpi=150)\n",
    "\n",
    "# Model fit for out-of-sample data looks best for the dmpfc input-HMM!\n",
    "\n",
    "####################################################\n",
    "filein = open(f'{out_dir}/Vanilla-HMM-k3.obj', 'rb')\n",
    "hmm1 = pickle.load(filein)\n",
    "hmm_z = hmm1.most_likely_states(reduced.drop(columns='Subject').values)\n",
    "\n",
    "filein = open(f'{out_dir}/Input-HMM-Amygdala-k3.obj', 'rb')\n",
    "hmm2 = pickle.load(filein)\n",
    "hmm2_z = hmm2.most_likely_states(reduced.drop(columns='Subject').values,input=source[['Amygdala']].values)\n",
    "hmm2.permute(find_permutation(hmm_z, hmm2_z))\n",
    "hmm2_states = hmm2.most_likely_states(reduced.drop(columns='Subject').values,input=source[['Amygdala']].values)\n",
    "    \n",
    "filein = open(f'{out_dir}/Input-HMM-DMPFC-k3.obj', 'rb')\n",
    "hmm3= pickle.load(filein)\n",
    "hmm3_z = hmm3.most_likely_states(reduced.drop(columns='Subject').values,input=source[['DMPFC']].values)\n",
    "hmm3.permute(find_permutation(hmm_z, hmm3_z))\n",
    "hmm3_states = hmm3.most_likely_states(reduced.drop(columns='Subject').values,input=source[['DMPFC']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Individual Input HMMs on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_iters = 500\n",
    "k = 3\n",
    "Amygdala = source_test[['Amygdala', 'Subject']]\n",
    "DMPFC = source_test[['DMPFC', 'Subject']]\n",
    "\n",
    "for subj in tqdm(reduced_test['Subject'].unique()):\n",
    "    hmm1ss = ssm.HMM(k, reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').shape[1], observations=\"diagonal_gaussian\")\n",
    "    tmp = hmm1ss.fit(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, method=\"em\", num_iters=N_iters)\n",
    "    filehandler = open(f'{out_dir}/{subj}-Vanilla-HMM-k3.obj', 'wb')\n",
    "    pickle.dump(hmm1ss, filehandler)\n",
    "    \n",
    "    inputhmm1ss = ssm.HMM(k, reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').shape[1], Amygdala[Amygdala['Subject']==subj].drop(columns='Subject').shape[1], observations=\"diagonal_gaussian\", transitions=\"inputdriven\")\n",
    "    tmp = inputhmm1ss.fit(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, inputs=Amygdala[Amygdala['Subject']==subj].drop(columns='Subject').values, method=\"em\", num_iters=N_iters)\n",
    "    filehandler = open(f'{out_dir}/{subj}-Input-HMM-Amygdala-k3.obj', 'wb')\n",
    "    pickle.dump(inputhmm1ss, filehandler)\n",
    "    \n",
    "    inputhmm2ss = ssm.HMM(k, reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').shape[1], DMPFC[DMPFC['Subject']==subj].drop(columns='Subject').shape[1], observations=\"diagonal_gaussian\", transitions=\"inputdriven\")\n",
    "    tmp = inputhmm2ss.fit(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, inputs=DMPFC[DMPFC['Subject']==subj].drop(columns='Subject').values, method=\"em\", num_iters=N_iters)\n",
    "    filehandler = open(f'{out_dir}/{subj}-Input-HMM-DMPFC-k3.obj', 'wb')\n",
    "    pickle.dump(inputhmm2ss, filehandler)\n",
    "\n",
    "\n",
    "# Load in subject model, align test Vanilla HMM with subject from Vanilla HMM\n",
    "# from train data, get most\n",
    "# likely states, probability of states, transition matrix, transition weights.\n",
    "# Use Vanilla HMM from each subject to align Input HMMs\n",
    "test_subs = reduced_test['Subject'].unique()\n",
    "train_subs = reduced['Subject'].unique()\n",
    "\n",
    "\n",
    "\n",
    "states_Out_m1 = pd.DataFrame()\n",
    "transmat_Out_m1 = pd.DataFrame()\n",
    "states_Out_m2 = pd.DataFrame()\n",
    "transmat_Out_m2 = pd.DataFrame()\n",
    "transweight_Out_m2 = pd.DataFrame()\n",
    "states_Out_m3 = pd.DataFrame()\n",
    "transmat_Out_m3 = pd.DataFrame()\n",
    "transweight_Out_m3 = pd.DataFrame()\n",
    "\n",
    "for subj in tqdm(test_subs):\n",
    "    \n",
    "    # Vanilla HMM\n",
    "    States = pd.DataFrame()\n",
    "    tmp_z = []\n",
    "    filein = open(f'{out_dir}/{subj}-Vanilla-HMM-k3.obj', 'rb')\n",
    "    hmm1ss = pickle.load(filein)\n",
    "    # Align with subject from Group HMM from test data\n",
    "    tmp_z = hmm1ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values)\n",
    "    hmm1ss.permute(find_permutation(hmm_z[0:1364], tmp_z))\n",
    "    filehandler = open(f'{out_dir}/{subj}-ALIGNED-Vanilla-HMM-k3.obj', 'wb')\n",
    "    pickle.dump(hmm1ss, filehandler)\n",
    "    # Most likely states (using Viterbi)\n",
    "    States['Viterbi'] = hmm1ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values)\n",
    "    # Probability of each state\n",
    "    posterior_probs = hmm1ss.expected_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values)\n",
    "    for i in range(k):\n",
    "        States[f'Probability_{i}'] = posterior_probs[0][:,i]\n",
    "\n",
    "    States['Subject'] = subj\n",
    "    states_Out_m1 = states_Out_m1.append(States)\n",
    "\n",
    "    # Transition matrix\n",
    "    trans_mat = np.exp(hmm1ss.transitions.log_Ps)\n",
    "    T = pd.DataFrame(trans_mat)\n",
    "    T['Subject'] = subj\n",
    "    transmat_Out_m1 = transmat_Out_m1.append(T)\n",
    "       \n",
    "\n",
    "    # Input HMM Amygdala\n",
    "    States = pd.DataFrame()\n",
    "    tmp_z = []\n",
    "    filein = open(f'{out_dir}/{subj}-Input-HMM-Amygdala-k3.obj', 'rb')\n",
    "    inputhmm1ss = pickle.load(filein)\n",
    "    # Align with self from Vanilla HMM from test data\n",
    "    self_z = hmm1ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values)\n",
    "    tmp_z = inputhmm1ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, Amygdala[Amygdala['Subject']==subj].drop(columns='Subject').values)\n",
    "    inputhmm1ss.permute(find_permutation(self_z, tmp_z))\n",
    "    filehandler = open(f'{out_dir}/{subj}-ALIGNED-Input-HMM-Amygdala-k3.obj', 'wb')\n",
    "    pickle.dump(inputhmm1ss, filehandler)\n",
    "    # Most likely states (using Viterbi)\n",
    "    States['Viterbi'] = inputhmm1ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, Amygdala[Amygdala['Subject']==subj].drop(columns='Subject').values)\n",
    "    # Probability of each state\n",
    "    posterior_probs = inputhmm1ss.expected_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, Amygdala[Amygdala['Subject']==subj].drop(columns='Subject').values)\n",
    "    for i in range(k):\n",
    "        States[f'Probability_{i}'] = posterior_probs[0][:,i]\n",
    "\n",
    "    States['Subject'] = subj\n",
    "    states_Out_m2 = states_Out_m2.append(States)\n",
    "\n",
    "    # Transition matrix\n",
    "    trans_mat = np.exp(inputhmm1ss.transitions.log_Ps)\n",
    "    T = pd.DataFrame(trans_mat)\n",
    "    T['Subject'] = subj\n",
    "    transmat_Out_m2 = transmat_Out_m2.append(T)\n",
    "    \n",
    "    # Transition Input Weight\n",
    "    Ws = pd.DataFrame(inputhmm1ss.transitions.Ws)\n",
    "    Ws['Subject'] = subj\n",
    "    transweight_Out_m2 = transweight_Out_m2.append(Ws)\n",
    "    \n",
    "\n",
    "\n",
    "    # Input HMM DMPFC\n",
    "\n",
    "    States = pd.DataFrame()\n",
    "    tmp_z = []\n",
    "    filein = open(f'{out_dir}/{subj}-Input-HMM-DMPFC-k3.obj', 'rb')\n",
    "    inputhmm2ss = pickle.load(filein)\n",
    "    # Align with self from Vanilla HMM from test data\n",
    "    self_z = hmm1ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values)\n",
    "    tmp_z = inputhmm2ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, DMPFC[DMPFC['Subject']==subj].drop(columns='Subject').values)\n",
    "    inputhmm2ss.permute(find_permutation(self_z, tmp_z))\n",
    "    filehandler = open(f'{out_dir}/{subj}-ALIGNED-Input-HMM-DMPFC-k3.obj', 'wb')\n",
    "    pickle.dump(inputhmm2ss, filehandler)\n",
    "    # Most likely states (using Viterbi)\n",
    "    States['Viterbi'] = inputhmm2ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, DMPFC[DMPFC['Subject']==subj].drop(columns='Subject').values)\n",
    "    # Probability of each state\n",
    "    posterior_probs = inputhmm2ss.expected_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, DMPFC[DMPFC['Subject']==subj].drop(columns='Subject').values)\n",
    "    for i in range(k):\n",
    "        States[f'Probability_{i}'] = posterior_probs[0][:,i]\n",
    "\n",
    "    States['Subject'] = subj\n",
    "    states_Out_m3 = states_Out_m3.append(States)\n",
    "\n",
    "    # Transition matrix\n",
    "    trans_mat = np.exp(inputhmm2ss.transitions.log_Ps)\n",
    "    T = pd.DataFrame(trans_mat)\n",
    "    T['Subject'] = subj\n",
    "    transmat_Out_m3 = transmat_Out_m3.append(T)\n",
    "    \n",
    "    # Transition Input Weight\n",
    "    Ws = pd.DataFrame(inputhmm2ss.transitions.Ws)\n",
    "    Ws['Subject'] = subj\n",
    "    transweight_Out_m3 = transweight_Out_m3.append(Ws)\n",
    "    \n",
    "states_Out_m1.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Vanilla-HMM-PredictedStates-k3.csv'))\n",
    "transmat_Out_m1.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Vanilla-HMM-TransitionMatrix-k3.csv')) \n",
    "\n",
    "states_Out_m2.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-Amygdala-PredictedStates-k3.csv'))\n",
    "transmat_Out_m2.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-Amygdala-TransitionMatrix-k3.csv'))  \n",
    "transweight_Out_m2.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-Amygdala-TransitionWeights-k3.csv'))\n",
    "  \n",
    "states_Out_m3.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-DMPFC-PredictedStates-k3.csv'))\n",
    "transmat_Out_m3.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-DMPFC-TransitionMatrix-k3.csv'))  \n",
    "transweight_Out_m3.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-DMPFC-TransitionWeights-k3.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average the Transition Matrices, Weights and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in matrices\n",
    "hmm1ss_transmat = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Vanilla-HMM-TransitionMatrix-k3.csv'), index_col=0)\n",
    "inputhmm1ss_transmat = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-Amygdala-TransitionMatrix-k3.csv'), index_col=0)\n",
    "inputhmm2ss_transmat = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-DMPFC-TransitionMatrix-k3.csv'), index_col=0)\n",
    "\n",
    "# Mean\n",
    "hmm1ss_transmat_mean = hmm1ss_transmat.groupby(hmm1ss_transmat.index).mean()\n",
    "inputhmm1ss_transmat_mean = inputhmm1ss_transmat.groupby(inputhmm1ss_transmat.index).mean()\n",
    "inputhmm2ss_transmat_mean = inputhmm2ss_transmat.groupby(inputhmm2ss_transmat.index).mean()\n",
    "\n",
    "# Tstat and pval  \n",
    "inputhmm1ss_hmm1ss = inputhmm1ss_transmat.drop(columns='Subject') - hmm1ss_transmat.drop(columns='Subject')\n",
    "inputhmm1ss_tstat = inputhmm1ss_hmm1ss.groupby(inputhmm1ss_hmm1ss.index).mean()/inputhmm1ss_hmm1ss.groupby(inputhmm1ss_hmm1ss.index).sem()\n",
    "inputhmm1ss_pval = stats.t.sf(abs(inputhmm1ss_tstat), df=16)\n",
    "\n",
    "inputhmm2ss_hmm1ss = inputhmm2ss_transmat.drop(columns='Subject') - hmm1ss_transmat.drop(columns='Subject')\n",
    "inputhmm2ss_tstat = inputhmm2ss_hmm1ss.groupby(inputhmm2ss_hmm1ss.index).mean()/inputhmm2ss_hmm1ss.groupby(inputhmm2ss_hmm1ss.index).sem()\n",
    "inputhmm2ss_pval = stats.t.sf(abs(inputhmm2ss_tstat), df=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Transition Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = k \n",
    "    \n",
    "fig = plt.figure(figsize=(9, 4), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(hmm1ss_transmat_mean, vmin=-1, vmax=1, cmap='bone')\n",
    "for i in range(hmm1ss_transmat_mean.shape[0]):\n",
    "    for j in range(hmm1ss_transmat_mean.shape[1]):\n",
    "        text = plt.text(j, i, str(np.around(hmm1ss_transmat_mean.values[i, j], decimals=2)), ha=\"center\", va=\"center\",\n",
    "                        color=\"k\", fontsize=12)\n",
    "plt.xlim(-0.5, num_states - 0.5)\n",
    "plt.xticks(range(0, num_states), ('1', '2', '3'), fontsize=10)\n",
    "plt.yticks(range(0, num_states), ('1', '2', '3'), fontsize=10)\n",
    "plt.ylim(k - 0.5, -0.5)\n",
    "plt.ylabel(\"state t\", fontsize = 15)\n",
    "plt.xlabel(\"state t+1\", fontsize = 15)\n",
    "plt.title(\"HMM\", fontsize = 15)   \n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(inputhmm1ss_transmat_mean, vmin=-1, vmax=1, cmap='bone')\n",
    "for i in range(inputhmm1ss_transmat_mean.shape[0]):\n",
    "    for j in range(inputhmm1ss_transmat_mean.shape[1]):\n",
    "        text = plt.text(j, i, str(np.around(inputhmm1ss_transmat_mean.values[i, j], decimals=2)), ha=\"center\", va=\"center\",\n",
    "                        color=\"k\", fontsize=12)\n",
    "plt.xlim(-0.5, num_states - 0.5)\n",
    "plt.xticks(range(0, k), ('1', '2', '3'), fontsize=10)\n",
    "plt.yticks(range(0, k), ('1', '2', '3'), fontsize=10)\n",
    "plt.ylim(k - 0.5, -0.5)\n",
    "plt.ylabel(\"state t\", fontsize = 15)\n",
    "plt.xlabel(\"state t+1\", fontsize = 15)\n",
    "plt.title(\"Input HMM Amygdala\", fontsize = 15) \n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(inputhmm2ss_transmat_mean, vmin=-1, vmax=1, cmap='bone')\n",
    "for i in range(inputhmm2ss_transmat_mean.shape[0]):\n",
    "    for j in range(inputhmm2ss_transmat_mean.shape[1]):\n",
    "        text = plt.text(j, i, str(np.around(inputhmm2ss_transmat_mean.values[i, j], decimals=2)), ha=\"center\", va=\"center\",\n",
    "                        color=\"k\", fontsize=12)\n",
    "plt.xlim(-0.5, num_states - 0.5)\n",
    "plt.xticks(range(0, k), ('1', '2', '3'), fontsize=10)\n",
    "plt.yticks(range(0, k), ('1', '2', '3'), fontsize=10)\n",
    "plt.ylim(k - 0.5, -0.5)\n",
    "plt.ylabel(\"state t\", fontsize = 15)\n",
    "plt.xlabel(\"state t+1\", fontsize = 15)\n",
    "plt.title(\"Input HMM DMPFC\", fontsize = 15) \n",
    "plt.subplots_adjust(0, 0, 1, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()  \n",
    "fig.savefig('MeanTransitionMatrices-k3-4.15.22.png', dpi=150)\n",
    "    \n",
    "# Plot p-vals of change in transition matrices. Shade of cell is -log10(p)\n",
    "fig = plt.figure(figsize=(7, 4), dpi=80, facecolor='w', edgecolor='k')    \n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(-np.log10(inputhmm1ss_pval), vmin=0, vmax=5, cmap='bone')\n",
    "for i in range(inputhmm1ss_pval.shape[0]):\n",
    "    for j in range(inputhmm1ss_pval.shape[1]):\n",
    "        text = plt.text(j, i, str(np.around(inputhmm1ss_pval[i, j], decimals=4)), ha=\"center\", va=\"center\",\n",
    "                        color=\"k\", fontsize=12)\n",
    "plt.xlim(-0.5, num_states - 0.5)\n",
    "plt.xticks(range(0, k), ('1', '2', '3'), fontsize=10)\n",
    "plt.yticks(range(0, k), ('1', '2', '3'), fontsize=10)\n",
    "plt.ylim(k - 0.5, -0.5)\n",
    "plt.ylabel(\"state t\", fontsize = 15)\n",
    "plt.xlabel(\"state t+1\", fontsize = 15)\n",
    "plt.title(\"Input HMM Amygdala pval\", fontsize = 15) \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(-np.log10(inputhmm2ss_pval), vmin=0, vmax=5, cmap='bone')\n",
    "for i in range(inputhmm2ss_pval.shape[0]):\n",
    "    for j in range(inputhmm2ss_pval.shape[1]):\n",
    "        text = plt.text(j, i, str(np.around(inputhmm2ss_pval[i, j], decimals=4)), ha=\"center\", va=\"center\",\n",
    "                        color=\"k\", fontsize=12)\n",
    "plt.xlim(-0.5, num_states - 0.5)\n",
    "plt.xticks(range(0, k), ('1', '2', '3'), fontsize=10)\n",
    "plt.yticks(range(0, k), ('1', '2', '3'), fontsize=10)\n",
    "plt.ylim(k - 0.5, -0.5)\n",
    "plt.ylabel(\"state t\", fontsize = 15)\n",
    "plt.xlabel(\"state t+1\", fontsize = 15)\n",
    "plt.title(\"Input HMM DMPFC pval\", fontsize = 15) \n",
    "plt.subplots_adjust(0, 0, 1, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()     \n",
    "fig.savefig('DiffFromVanillaHMM-pvals-k3-4.15.22.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Transition Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in weights\n",
    "inputhmm1ss_Ws = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-Amygdala-TransitionWeights-k3.csv'), index_col=0)\n",
    "inputhmm2ss_Ws = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-DMPFC-TransitionWeights-k3.csv'), index_col=0)\n",
    "\n",
    "# Means\n",
    "inputhmm1ss_Ws_mean = inputhmm1ss_Ws.groupby(inputhmm1ss_Ws.index).mean()\n",
    "inputhmm2ss_Ws_mean = inputhmm2ss_Ws.groupby(inputhmm2ss_Ws.index).mean()\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(k), inputhmm1ss_Ws_mean, color=colors[2], marker='o',\n",
    "         lw=2.5, markeredgewidth=2.5, markerfacecolor='white', markersize=12, linestyle = '-',\n",
    "         label=\"Amygdala\")\n",
    "plt.plot(range(k), inputhmm2ss_Ws_mean, color=colors[3], marker='o',\n",
    "         lw=2.5, markeredgewidth=2.5, markerfacecolor='white', markersize=12, linestyle = '-',\n",
    "         label=\"DMPFC\")\n",
    "plt.yticks(fontsize=10)\n",
    "plt.ylabel(\"Mean input weight\", fontsize=15)\n",
    "plt.ylim([-.4, .4])\n",
    "plt.yticks([-.4, -.2, 0, .2, .4], fontsize=12)\n",
    "plt.xlabel(\"State\", fontsize=15)\n",
    "plt.xticks([0, 1,2], ['1', '2', '3'], fontsize=12)\n",
    "plt.axhline(y=0, color=\"k\", alpha=0.5, ls=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"Weight recovery\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "fig.savefig('InputHMM-Weights-k3-4.15.22.png', dpi=150)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of each state   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla HMM\n",
    "all_sequence_counts = []\n",
    "for subj in tqdm(test_subs):\n",
    "    filein = open(f'{out_dir}/{subj}-Aligned-Vanilla-HMM-k3.obj', 'rb')\n",
    "    hmm1ss = pickle.load(filein)\n",
    "    inferred_state_list, inferred_durations = ssm.util.rle(hmm1ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values))\n",
    "    sequence_count = pd.DataFrame()\n",
    "    sequence_count['State'] = inferred_state_list\n",
    "    sequence_count['Count'] = inferred_durations\n",
    "    sequence_count['Subject'] = subj\n",
    "    sequence_count['ROI'] = 'vmpfc'\n",
    "    all_sequence_counts.append(sequence_count)\n",
    "all_sequence_counts = pd.concat(all_sequence_counts, axis=0)\n",
    "all_sequence_counts.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Vanilla-HMM-StateDurations-k3.csv'))\n",
    "\n",
    "# Input HMM Amygdala\n",
    "all_sequence_counts = []\n",
    "for subj in tqdm(test_subs):\n",
    "    filein = open(f'{out_dir}/{subj}-Aligned-Input-HMM-Amygdala-k3.obj', 'rb')\n",
    "    inputhmm1ss = pickle.load(filein)\n",
    "    inferred_state_list, inferred_durations = ssm.util.rle(inputhmm1ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, Amygdala[Amygdala['Subject']==subj].drop(columns='Subject').values))\n",
    "    sequence_count = pd.DataFrame()\n",
    "    sequence_count['State'] = inferred_state_list\n",
    "    sequence_count['Count'] = inferred_durations\n",
    "    sequence_count['Subject'] = subj\n",
    "    sequence_count['ROI'] = 'vmpfc'\n",
    "    all_sequence_counts.append(sequence_count)\n",
    "all_sequence_counts = pd.concat(all_sequence_counts, axis=0)\n",
    "all_sequence_counts.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-Amygdala-StateDurations-k3.csv'))\n",
    "\n",
    "# Input HMM DMPFC\n",
    "all_sequence_counts = []\n",
    "for subj in tqdm(test_subs):\n",
    "    filein = open(f'{out_dir}/{subj}-Aligned-Input-HMM-DMPFC-k3.obj', 'rb')\n",
    "    inputhmm1ss = pickle.load(filein)\n",
    "    inferred_state_list, inferred_durations = ssm.util.rle(inputhmm1ss.most_likely_states(reduced_test[reduced_test['Subject']==subj].drop(columns='Subject').values, DMPFC[DMPFC['Subject']==subj].drop(columns='Subject').values))\n",
    "    sequence_count = pd.DataFrame()\n",
    "    sequence_count['State'] = inferred_state_list\n",
    "    sequence_count['Count'] = inferred_durations\n",
    "    sequence_count['Subject'] = subj\n",
    "    sequence_count['ROI'] = 'vmpfc'\n",
    "    all_sequence_counts.append(sequence_count)\n",
    "all_sequence_counts = pd.concat(all_sequence_counts, axis=0)\n",
    "all_sequence_counts.to_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-DMPFC-StateDurations-k3.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot state durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sequence_counts = []\n",
    "hmm1ss_seq = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Vanilla-HMM-StateDurations-k3.csv'), index_col=0)\n",
    "hmm1ss_seq['Model'] = 'Vanilla HMM'\n",
    "all_sequence_counts.append(hmm1ss_seq)\n",
    "inputhmm1ss_seq = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-Amygdala-StateDurations-k3.csv'), index_col=0)\n",
    "inputhmm1ss_seq['Model'] = 'Input HMM Amygdala'\n",
    "all_sequence_counts.append(inputhmm1ss_seq)\n",
    "inputhmm2ss_seq = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-DMPFC-StateDurations-k3.csv'), index_col=0)\n",
    "inputhmm2ss_seq['Model'] = 'Input HMM DMPFC'\n",
    "all_sequence_counts.append(inputhmm2ss_seq)\n",
    "all_sequence_counts = pd.concat(all_sequence_counts, axis=0) \n",
    "\n",
    "max_length = 25\n",
    "fig = plt.figure(figsize=(15, 5), dpi=100, facecolor='w', edgecolor='k')\n",
    "with sns.plotting_context(context='paper', font_scale=2):\n",
    "    f,a = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharex=True, sharey=False)\n",
    "    for i,model in enumerate(['Vanilla HMM','Input HMM Amygdala', 'Input HMM DMPFC']):\n",
    "        tmp_data = all_sequence_counts.query('Model==@model')\n",
    "        for state in tmp_data['State'].unique():\n",
    "            sns.distplot(tmp_data.query('State==@state')['Count'], hist=False, kde_kws={\"shade\": True}, ax=a[i])\n",
    "        a[i].set_xlim(0, max_length)\n",
    "        a[i].set_ylim(0, 0.25)\n",
    "        a[i].legend(['State1','State2','State3'])\n",
    "        a[i].set_xlabel('State Duration (TR)')\n",
    "        a[i].set_ylabel('Frequency')\n",
    "        a[i].set_title(f'{model}')\n",
    "plt.tight_layout()\n",
    "f.savefig('MeanStateDurations-k3-4.15.22.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot example participants states and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subs = reduced_test['Subject'].unique()\n",
    "\n",
    "\n",
    "hmm1ss_states = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Vanilla-HMM-PredictedStates-k3.csv'))\n",
    "inputhmm1ss_states = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-Amygdala-PredictedStates-k3.csv'))\n",
    "inputhmm2ss_states = pd.read_csv(os.path.join(out_dir, f'Test-ALIGNED-Input-HMM-DMPFC-PredictedStates-k3.csv'))\n",
    "\n",
    "# Example subject #1\n",
    "example_subs = test_subs[np.random.randint(0, 17,1)].tolist()\n",
    "fig = plt.figure(figsize=(12, 10), dpi=100, facecolor='w', edgecolor='k')\n",
    "with sns.plotting_context(context='paper', font_scale=2):\n",
    "\n",
    "    plt.subplot(511)\n",
    "    tmp_data = hmm1ss_states[hmm1ss_states['Subject']==example_subs[0]]['Viterbi'].values\n",
    "    plt.imshow(tmp_data[None,:], aspect=\"auto\", cmap=cmap, vmin=0, vmax=len(colors)-1)\n",
    "    plt.ylabel(\"Vanilla HMM\", fontsize=12)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.title(f\"Most Likely States - {example_subs[0]}\", fontsize=15)\n",
    "    \n",
    "    plt.subplot(512)\n",
    "    tmp_data = source_test[source_test['Subject']==example_subs[0]]['Amygdala'].values\n",
    "    plt.plot(tmp_data, color='black', linewidth=2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlim(0, tmp_data.shape[0])\n",
    "    plt.ylabel(\"Amygdala\\nInput\", fontsize=12)\n",
    "\n",
    "    plt.subplot(513)\n",
    "    tmp_data = inputhmm1ss_states[inputhmm1ss_states['Subject']==example_subs[0]]['Viterbi'].values\n",
    "    plt.imshow(tmp_data[None,:], aspect=\"auto\", cmap=cmap, vmin=0, vmax=len(colors)-1)\n",
    "    plt.ylabel(\"Input HMM\\nAmygdala\", fontsize=12)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(514)\n",
    "    tmp_data = source_test[source_test['Subject']==example_subs[0]]['DMPFC'].values\n",
    "    plt.plot(tmp_data, color='black', linewidth=2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlim(0, tmp_data.shape[0])\n",
    "    plt.ylabel(\"DMPFC\\nInput\", fontsize=12)\n",
    "    \n",
    "    plt.subplot(515)\n",
    "    tmp_data = inputhmm2ss_states[inputhmm2ss_states['Subject']==example_subs[0]]['Viterbi'].values\n",
    "    plt.imshow(tmp_data[None,:], aspect=\"auto\", cmap=cmap, vmin=0, vmax=len(colors)-1)\n",
    "    plt.ylabel(\"Input HMM\\nDMPFC\", fontsize=12)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"time\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    example_subs[0]\n",
    "fig.savefig(f'LikelyStates-{example_subs[0]}.png', dpi=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
